{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as pp\n",
    "from pathlib import Path\n",
    "\n",
    "from speech2text.audio_data import WavData, PdData, NpData\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FILE_ROOT_PATH = Path(\"../../tests/audio_samples\")\n",
    "IN_FILE_PATH = IN_FILE_ROOT_PATH / \"en_chunk.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WavData demo\n",
    "\n",
    "wav_data = WavData.load_from_wav_file(IN_FILE_PATH)\n",
    "wav_data.ipy_show_player()\n",
    "wav_data.ipy_show_specgram()\n",
    "\n",
    "empty = WavData(wav_data.pcm_params)\n",
    "for chunk in wav_data.split_in_chunks():\n",
    "    empty.append_chunk(chunk)\n",
    "assert wav_data.raw_data == empty.raw_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyDub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PdAudio demo\n",
    "\n",
    "audio: PdData = PdData.load_from_wav_file(IN_FILE_PATH)\n",
    "audio.ipy_show_player()\n",
    "audio.ipy_show_specgram()\n",
    "pp(audio.dBFS)\n",
    "audio = audio.adjust_pcm_params()\n",
    "audio.ipy_show_player()\n",
    "audio.ipy_show_specgram()\n",
    "pp(audio.dBFS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut off frequancies\n",
    "audio_ = audio[:]\n",
    "audio_ = audio_.high_pass_filter(300)\n",
    "audio_ = audio_.low_pass_filter(3500)\n",
    "audio.ipy_show_specgram()\n",
    "audio_.ipy_show_player()\n",
    "audio_.ipy_show_specgram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed up, Volum up\n",
    "\n",
    "audio_ = audio[:]\n",
    "audio_ = audio_.speedup(1.2)\n",
    "audio_.ipy_show_player()\n",
    "\n",
    "audio_ += 5\n",
    "audio_.ipy_show_player()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence splitting\n",
    "audio_ = audio[:]\n",
    "audio_ = (\n",
    "    PdData\n",
    "    .load_from_wav_file(IN_FILE_ROOT_PATH / \"en_hedgehog.wav\")\n",
    "    # .speedup(1.2)\n",
    "    .low_pass_filter(300)\n",
    "    .high_pass_filter(3500)\n",
    "    .adjust_pcm_params()\n",
    "    .normalize()\n",
    "    # + 5 # make it louder\n",
    ")\n",
    "audio_.ipy_show_player()\n",
    "\n",
    "pp(\"===\"*10)\n",
    "segments = audio_.split_on_silence(\n",
    "    min_silence_len = 1000,\n",
    "    silence_thresh = -30,\n",
    "    keep_silence = 1000,\n",
    "    seek_step = 10\n",
    ")\n",
    "for i in range(min(10, len(segments))):\n",
    "    segments[i].ipy_show_player()\n",
    "    segments[i].ipy_show_specgram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `np`-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(NpData.__bases__)\n",
    "np_data = NpData.load_from_pd_data(audio)\n",
    "display(np_data.__class__)\n",
    "np_data.ipy_show_player(); np_data.ipy_show_specgram()\n",
    "\n",
    "assert np_data.pcm_params == audio.pcm_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 `noisereduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech2text.transcriber.tools import reduce_noise\n",
    "\n",
    "np_data_ = reduce_noise(np_data)\n",
    "np_data.ipy_show_player(); np_data.ipy_show_specgram()\n",
    "np_data_.ipy_show_player(); np_data_.ipy_show_specgram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 `whisper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech2text.transcriber.tools import transcribe, _pick_whisper_model\n",
    "\n",
    "_pick_whisper_model(\"small.en\")\n",
    "_pick_whisper_model(\"tiny.en\")\n",
    "\n",
    "whisper_model_params = {\n",
    "    \"verbose\": False,\n",
    "    \"temperature\": (0, 0.2, 0.4, 0.6, 0.8, 1),\n",
    "    \"compression_ratio_threshold\": 2.4,\n",
    "    \"no_speech_threshold\": 0.6,\n",
    "    \"condition_on_previous_text\": True,\n",
    "    \"initial_prompt\": None,\n",
    "    \"word_timestamps\": False,\n",
    "    \"clip_timestamps\": \"0\",\n",
    "    \"hallucination_silence_threshold\": None,\n",
    "}\n",
    "speed_up = 1.0\n",
    "min_silence_len = 800\n",
    "\n",
    "\n",
    "\n",
    "min_silence_len = int(min_silence_len / speed_up)\n",
    "audio = (\n",
    "    PdData\n",
    "    .load_from_wav_file(IN_FILE_ROOT_PATH / \"en_hedgehog.wav\")\n",
    "    .speedup(speed_up)\n",
    "    .low_pass_filter(300)\n",
    "    .high_pass_filter(3500)\n",
    "    .adjust_pcm_params()\n",
    "    .normalize()\n",
    "    # + 5 # make it louder\n",
    ")\n",
    "audio.ipy_show_player()\n",
    "segments = audio.split_on_silence(\n",
    "    min_silence_len=min_silence_len,\n",
    "    silence_thresh=-30,\n",
    "    keep_silence=min_silence_len,\n",
    "    seek_step=10,\n",
    ")\n",
    "\n",
    "for segment in segments[:10]:\n",
    "    np_segment = NpData.load_from_pd_data(segment)\n",
    "    np_segment = reduce_noise(np_segment)\n",
    "\n",
    "    tr_segment = transcribe(np_segment, **whisper_model_params)\n",
    "    np_segment.ipy_show_player()\n",
    "    pp(tr_segment[\"text\"])\n",
    "    np_segment.ipy_show_specgram(dpi=40)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunck queue pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from speech2text.transcriber.tools import transcribe, reduce_noise\n",
    "\n",
    "wav_data = (\n",
    "    PdData\n",
    "    .load_from_wav_file(IN_FILE_ROOT_PATH / \"en_chunk.wav\")\n",
    "    .adjust_pcm_params()\n",
    "    .create_wav_data()\n",
    ") # en_hedgehog.wav en_news.wav en_chunk.wav\n",
    "\n",
    "\n",
    "pcm_params = wav_data.pcm_params\n",
    "\n",
    "def chunk_iterator(chunk_len_sec: float):\n",
    "    for chunk in wav_data.split_in_chunks(chunk_len_sec):\n",
    "        yield chunk\n",
    "        \n",
    "sos_params = {\n",
    "    \"min_silence_len\": 1000,\n",
    "    \"silence_thresh\": -30,\n",
    "    \"keep_silence\": 800,\n",
    "    \"seek_step\": 10,\n",
    "}\n",
    "\n",
    "text_lines: List[str] = []\n",
    "previous_pd_blocks: List[PdData] = []\n",
    "current_block: WavData  = None\n",
    "current_block_text = None\n",
    "\n",
    "for chunk in chunk_iterator(0.8):\n",
    "    if current_block is None:\n",
    "        current_block = WavData(pcm_params)\n",
    "    current_block.append_chunk(chunk)\n",
    "    pd_block = PdData.load_from_wav_file(current_block)\n",
    "    # pd_block.ipy_show_player()\n",
    "    previous_pd_blocks = pd_block.split_on_silence(**sos_params)\n",
    "    if not previous_pd_blocks:\n",
    "        current_block = None\n",
    "        continue\n",
    "    pd_block = previous_pd_blocks.pop()\n",
    "\n",
    "    init_prompt = text_lines[-1] + \". \" if text_lines else None\n",
    "    for prev_block in previous_pd_blocks:\n",
    "        prev_block = (\n",
    "            prev_block\n",
    "            .low_pass_filter(300)\n",
    "            .high_pass_filter(3500)\n",
    "            .normalize()\n",
    "        )\n",
    "        np_data = NpData.load_from_pd_data(prev_block)\n",
    "        np_data = reduce_noise(np_data)\n",
    "        transcription = transcribe(\n",
    "            np_data,\n",
    "            \"tiny.en\",\n",
    "            initial_prompt=init_prompt, \n",
    "            # condition_on_previous_text=False,\n",
    "        )\n",
    "        init_prompt = transcription[\"text\"]\n",
    "        text_lines.append(transcription[\"text\"])\n",
    "\n",
    "    if previous_pd_blocks:\n",
    "        current_block = pd_block.create_wav_data()\n",
    "    np_data = NpData.load_from_pd_data(pd_block)\n",
    "    transcription = transcribe(\n",
    "        np_data,\n",
    "        \"tiny.en\",\n",
    "        initial_prompt=init_prompt, \n",
    "        # condition_on_previous_text=False,\n",
    "    )\n",
    "    current_block_text = transcription[\"text\"]\n",
    "    current_block.ipy_show_player()\n",
    "    pp(text_lines)\n",
    "    pp(current_block_text)\n",
    "\n",
    "# small.en - small.en\n",
    "# 1.5 >>= low_pass_filter + high_pass_filter + normalize + reduce_noise == 31/38\n",
    "# 1.5 >>= low_pass_filter + high_pass_filter + normalize == 27/38\n",
    "# 1.5 >>= reduce_noise == 25/38\n",
    "# 1.5 >>= == 25/38\n",
    "# 1.0 >>= == 33/38\n",
    "# 0.8 >>= == 56/38\n",
    "\n",
    "# tiny.en - small.en\n",
    "# 0.8 >>= == 22/38\n",
    "    \n",
    "# tiny.en - tiny.en\n",
    "# 0.8 >>= == 17/38\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
